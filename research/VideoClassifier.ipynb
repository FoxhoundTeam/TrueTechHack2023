{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/GantMan/nsfw_model.git  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mblRbfsItsUh",
        "outputId": "f531eee4-055c-4ec3-fe5b-a6accaccfbc1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nsfw_model'...\n",
            "remote: Enumerating objects: 481, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 481 (delta 33), reused 23 (delta 9), pack-reused 397\u001b[K\n",
            "Receiving objects: 100% (481/481), 470.33 KiB | 7.13 MiB/s, done.\n",
            "Resolving deltas: 100% (239/239), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFjzn4PFCNHp",
        "outputId": "208c80b1-973a-48af-d2ff-dfd35d65c1f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scenedetect[opencv]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMzPdgKf80rx",
        "outputId": "f53e5b1e-638a-43de-92af-e4543a711ab7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scenedetect[opencv]\n",
            "  Downloading scenedetect-0.6.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.9/dist-packages (from scenedetect[opencv]) (1.4.4)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.9/dist-packages (from scenedetect[opencv]) (8.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from scenedetect[opencv]) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from scenedetect[opencv]) (4.65.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (from scenedetect[opencv]) (4.7.0.72)\n",
            "Installing collected packages: scenedetect\n",
            "Successfully installed scenedetect-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.amazonaws.com/ir_public/ai/nsfw_models/nsfw.299x299.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I4yL3zU597r",
        "outputId": "7da41553-f8fd-44b7-e89e-fd0d8d624e86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-27 14:41:29--  https://s3.amazonaws.com/ir_public/ai/nsfw_models/nsfw.299x299.h5\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.120.128, 52.217.166.160, 52.216.33.104, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.120.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 158652512 (151M) [application/x-www-form-urlencoded]\n",
            "Saving to: ‘nsfw.299x299.h5’\n",
            "\n",
            "nsfw.299x299.h5     100%[===================>] 151.30M  31.5MB/s    in 5.6s    \n",
            "\n",
            "2023-03-27 14:41:35 (27.2 MB/s) - ‘nsfw.299x299.h5’ saved [158652512/158652512]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DQBS_-99Aubd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pytube import YouTube"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "PATH_TO_NSWF_MODEL = \"/content/nsfw_model\"\n",
        "if PATH_TO_NSWF_MODEL not in sys.path:\n",
        "    sys.path.append(PATH_TO_NSWF_MODEL)"
      ],
      "metadata": {
        "id": "wHgpDr115JBj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def download_video_from_youtube(urls, dir, file_extension=\"mp4\", resolution=\"360p\"):\n",
        "    if isinstance(urls, str):\n",
        "        urls = [urls]\n",
        "    for url in tqdm(urls):\n",
        "        yt = YouTube(url)\n",
        "        stream = yt.streams.filter(file_extension=file_extension)\n",
        "        stream.get_by_resolution(resolution).download(dir)"
      ],
      "metadata": {
        "id": "W8kDN5PxNX6n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = \"https://www.youtube.com/watch?v=Fm_iyGAutqc\"\n",
        "download_video_from_youtube(urls, \"/content/\", resolution=\"360p\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZmxI3DKO4Xg",
        "outputId": "bd550586-7ff6-4d43-998b-1ed980a53100"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:09<00:00,  9.25s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from abc import ABC, abstractmethod\n",
        "from nsfw_detector import predict\n",
        "from scenedetect import detect, ContentDetector, AdaptiveDetector\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "5314SQh7CwbM"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def central_crop(image):\n",
        "    center = image.shape\n",
        "    w = h = min(image.shape[:2])\n",
        "    x = center[1]/2 - w/2\n",
        "    y = center[0]/2 - h/2\n",
        "\n",
        "    crop_img = image[int(y):int(y+h), int(x):int(x+w)]\n",
        "    return crop_img\n"
      ],
      "metadata": {
        "id": "kP4UU_UG0dTA"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoClassifier(ABC):\n",
        "    \"\"\"Template of classifier class.\n",
        "\n",
        "    Attributes:\n",
        "    * input_dim - dimension of input for model.\n",
        "    * batch_size - is a batch size of frames to the model, classify \n",
        "    frames when they will gather in batch.\n",
        "    * threshold - is model threshold (prob_of_iclass > threshold => iclass).\n",
        "\n",
        "    Methods:\n",
        "    * predict - returns probs of frames.\n",
        "    * classify_scenes - return timecode and frames of scenes to censor\n",
        "    \"\"\"\n",
        "    @abstractmethod\n",
        "    def __init__(self, input_dim, batch_size, threshold):\n",
        "        self.batch_size = batch_size\n",
        "        self.input_dim = input_dim\n",
        "        self.central_crop = True\n",
        "        self.threshold = threshold\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(self, video_path, start_frame=0, end_frame=None, classify_every_n_frames=1):\n",
        "        \"\"\"Return probs of frames nswf classes starting from \n",
        "        `start_frame`(inclusive) to `end_frame`(exclusive) \n",
        "        with step `classify_every_n_frames`.\n",
        "\n",
        "        Example: {'number_of_frame':{'class':probability, ...}, ...}\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def classify_scenes(self, video_path, scenes=None, scene_threshold=.1, classify_every_n_frames=1):\n",
        "        \"\"\"Return List of tuples (start of the scene: FrameTimecode, end of the scene: FrameTimecode)\n",
        "        \n",
        "        Args:\n",
        "        * scenes - List of tuples of FrameTimecode to be classified. \n",
        "        If None than create with alghorithm. default None.\n",
        "        * scene_threshold - if number of scenes with nswf class > scene_threshold than add it to return.\n",
        "\n",
        "        FrameTimecode. https://scenedetect.com/projects/Manual/en/latest/api/frame_timecode.html#scenedetect-frame-timecode\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "    def _preprocess(self, frame):\n",
        "        frame = central_crop(frame) if self.central_crop else frame\n",
        "        resized_frame = cv2.resize(frame, (self.input_dim, self.input_dim))\n",
        "        resized_frame = resized_frame / 255\n",
        "        return resized_frame[np.newaxis, ...]"
      ],
      "metadata": {
        "id": "Y6OobglRWO88"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IntimateVideoClassifier(VideoClassifier):\n",
        "    def __init__(self, model_path, input_dim, batch_size, threshold=.8):\n",
        "        \"\"\"Note. input_dim = according to the weights of the model 224x224 or 299x299.\"\"\"\n",
        "        super().__init__(input_dim, batch_size, threshold)\n",
        "        self.model = predict.load_model(model_path)\n",
        "        self.central_crop = True\n",
        "\n",
        "    def predict(self, video_path, start_frame=0, end_frame=None, classify_every_n_frames=1):\n",
        "        frame_count = start_frame\n",
        "\n",
        "        batch = []\n",
        "        frames_idx = []\n",
        "        output = {}\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        # end frame or video length\n",
        "        end_frame = end_frame or int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        # set start frame\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "        while cap.isOpened() and (frame_count < end_frame):\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frame = self._preprocess(frame)\n",
        "                # collect frames to batch with indexes\n",
        "                frames_idx.append(frame_count)\n",
        "                batch.append(frame)\n",
        "                # process batch\n",
        "                if len(batch) >= self.batch_size:\n",
        "                    minibatch = np.concatenate(batch, axis=0)\n",
        "                    probs = predict.classify_nd(self.model, minibatch)\n",
        "                    output.update(dict(zip(frames_idx, probs)))\n",
        "                    # clear frames and indexes collections\n",
        "                    batch.clear()\n",
        "                    frames_idx.clear()\n",
        "\n",
        "                frame_count += classify_every_n_frames\n",
        "                # move forward for `classify_every_n_frames` frames\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
        "            else:\n",
        "                cap.release()\n",
        "                break\n",
        "\n",
        "        if len(batch) > 0:\n",
        "            minibatch = np.concatenate(batch, axis=0)\n",
        "            probs = predict.classify_nd(self.model, minibatch)\n",
        "            output.update(dict(zip(frames_idx, probs)))\n",
        "\n",
        "        return output\n",
        "\n",
        "    def classify_scenes(self, video_path, scenes=None, scene_threshold=.1, classify_every_n_frames=1):\n",
        "        scenes = scenes or detect(video_path, ContentDetector())\n",
        "        nswf_scenes = []\n",
        "        # TODO We create stream for every scene\n",
        "        for scene_start, scene_end in scenes:\n",
        "            scene_start_frame = scene_start.get_frames()\n",
        "            scene_end_frame = scene_end.get_frames()\n",
        "            scene_length = (scene_end_frame - scene_start_frame) / classify_every_n_frames\n",
        "\n",
        "            # TODO Highlight slow movments and blurry frames\n",
        "            probs = self.predict(video_path, \n",
        "                         start_frame=scene_start_frame, \n",
        "                         end_frame=scene_end_frame,\n",
        "                         classify_every_n_frames=classify_every_n_frames\n",
        "                         )\n",
        "            nswf_scenes_count = sum([\n",
        "                prob[\"porn\"] > self.threshold \n",
        "                or prob[\"hentai\"] > self.threshold \n",
        "                or prob[\"sexy\"] > self.threshold \n",
        "                for prob in probs.values()\n",
        "            ])\n",
        "            # print(scene_start_frame, scene_end_frame, \":\", (nswf_scenes_count / scene_length))\n",
        "            if (nswf_scenes_count / scene_length) > scene_threshold:\n",
        "                nswf_scenes.append((scene_start, scene_end))\n",
        "        return self.gluing(nswf_scenes)\n",
        "\n",
        "    @classmethod\n",
        "    def gluing(cls, raw_nswf_scenes):\n",
        "        \"\"\"Glue close frames.\"\"\"\n",
        "        nswf_scenes = []\n",
        "        for idx in range(len(raw_nswf_scenes)):\n",
        "            if len(nswf_scenes) > 0:\n",
        "                pred_end = nswf_scenes[-1][1].get_frames()\n",
        "                cur_start = raw_nswf_scenes[idx][0].get_frames()\n",
        "                if (cur_start - pred_end) < 20:\n",
        "                    nswf_scenes[-1] = (nswf_scenes[-1][0], raw_nswf_scenes[idx][1])\n",
        "                else:\n",
        "                    nswf_scenes.append(raw_nswf_scenes[idx])\n",
        "            else:    \n",
        "                nswf_scenes.append(raw_nswf_scenes[idx])\n",
        "        return nswf_scenes\n",
        "\n",
        "    def greedy_classify(self, video_path):\n",
        "        ...\n"
      ],
      "metadata": {
        "id": "bgpX1VSMUtdU"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = IntimateVideoClassifier(\"/content/nsfw.299x299.h5\", 299, 24)"
      ],
      "metadata": {
        "id": "YMD5198Ncth2"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/Глюк’оZа - Мотыльки (feat KYIVSTONER).mp4\""
      ],
      "metadata": {
        "id": "tANfT3L2iwAW"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = classifier.classify_scenes(video_path, scene_threshold=.3, classify_every_n_frames=1)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1iroKWndEN3",
        "outputId": "20d16141-d75d-4b38-cc0a-665047f74b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 320 x 180\n",
            "INFO:pyscenedetect:Detecting scenes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - ETA: 0s"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_video_fragment(video_path, fragment_path, start_frame=0, end_frame=None):\n",
        "    frame_count = start_frame\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    out = cv2.VideoWriter(fragment_path, fourcc, 20.0, (width,  height))\n",
        "    # end frame or video length\n",
        "    end_frame = end_frame or int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    # set start frame\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "    while cap.isOpened() and (frame_count < end_frame):\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            out.write(frame)\n",
        "            frame_count += 1\n",
        "        else:\n",
        "            cap.release()\n",
        "            out.release()\n",
        "            break"
      ],
      "metadata": {
        "id": "nAJDEdg1r49o"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (start, end) in enumerate(out):\n",
        "    srart = start.get_frames()\n",
        "    end = end.get_frames()\n",
        "    cut_video_fragment(video_path, f\"{video_path[:-4]}-{idx}.mp4\", srart, end)"
      ],
      "metadata": {
        "id": "7nJ8KGsbwhhL"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c7UQdn9pxkXQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}